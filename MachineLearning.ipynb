{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning**\n",
    "\n",
    "**Link codici** https://github.com/MaSTERmIKK/AulaMLandAI\n",
    "\n",
    "Il *machine learning* è un sottocampo dell'*intelligenza artificiale* che permette ai computer di imparare dai dati e migliorare le proprie prestazioni senza essere esplicitamente programmati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello è un costrutto matematico tra input e output desiderati. La costruzione avviene come segue:\n",
    "\n",
    "1. **Training**: Il modello viene realizzato tramite un processo di *addestramento*, ottimizzando i suoi parametri interni basandosi su un set di dati (*training set*).\n",
    "2. **Validation**: Dopo l'addestramento, i modelli vengono valutati su un set di dati di validazione (*validation set*) per regolare i parametri (*tuning*).\n",
    "3. **Testing**: Al termine testiamo il modello su un insieme di dati di test (*test set*) per valutare la performance finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fasi del Machine Learning**\n",
    "\n",
    "1. Caricamento e preprocessing dei dati\n",
    "2. Divisione del dataset in train e test test\n",
    "3. Addestramento del modello sul traing set\n",
    "4. Test del modello sul test set\n",
    "5. Valutazione del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apprendimento Supervisionato**\n",
    "Il modello viene addestrato su un set di dati che include sia gli input che gli output (dati *etichettati*). L'obiettivo è costruire un modello che possa fare previsioni accurate su nuovi dati basandosi su questa corrispondenza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelli di apprendimento supervisionato sono:\n",
    " * *Classificazione*\n",
    " * *Regressione*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apprendimento Non Supervisionato**\n",
    "\n",
    "Il modello lavora con dati che non hanno output (dati *non etichettati*). L'obiettivo è scoprire strutture nascoste dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelli di apprendimento non supervisionato sono:\n",
    "* *Clustering* : raggruppa i dati simili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apprendimento per Rinforzo**\n",
    "\n",
    "Tecnica in cui un agente impara a prendere decisione ottimizzando un sistema di ricompense e punizioni attraverso tentativi ed errori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overfitting e Underfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Overfitting**: si verifica quando un modello impara troppo bene i dettagli dei dati di addestramento, inclusi i rumori e le anomalie, a scapito delle prestazioni sui nuovi dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Underfitting**:  si verifica quando un modello è troppo semplice per catturare la struttura dei dati, risultando in una scarsa performance sia sui dati di addestramento che su quelli di test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scikit-learn**\n",
    "Utilizzata per metodi tradizionali di machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Caricamento e Preparazione dei Dati**\n",
    "Dopo aver caricato i dati, si preprocessano i dati per pulirli e normalizzarli, rendoli adatti all'analisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.datasets` fornisce funzioni per caricare dataset di esempio e per generare dataset sintetici, utili per testare algoritmi e apprendere come utilizzare scikit-learn.\n",
    "\n",
    "    * `load_iris()`, `load_digits()`, `load_wine()`: funzioni per caricare dataset di esempio.\n",
    "    \n",
    "    * `make_classification()`, `make_regression()`, `make_blobs()`: funzioni per generare dataset sintetici utili per test e simulazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.preprocessing` contiene strumenti per pre-processare i dati, come la scalatura, la normalizzazione, la codifica delle variabili categoriche e la gestione dei dati mancanti.\n",
    "\n",
    "    * `StandardScaler()`: effettua la standardizzazione delle caratteristiche, rendendo media = 0 e deviazione standard = 1.\n",
    "    \n",
    "    * `MinMaxScaler()`: scala le caratteristiche in un intervallo specificato.\n",
    "\n",
    "    * `OneHotEncoder()`: codifica variabili categoriche in vettori binari.\n",
    "\n",
    "    * `LabelEncoder()`: Codifica etichette target trasformandole in numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.feature_selection` offre metodi per selezionare le caratteristiche più rilevanti nei dati, migliorando l'efficienza e le prestazioni dei modelli attraverso tecniche come l'eliminazione univariata e la selezione ricorsiva di caratteristiche.\n",
    "\n",
    "    * `SelectKBest()`: seleziona le migliori K caratteristiche in base a una funzione statistica.\n",
    "    \n",
    "    * `RFE()`: *Recursive Feature Elimination*, rimuove iterativamente le caratteristiche meno rilevanti.\n",
    "\n",
    "    * `VarianceThreshold()`: rimuove le caratteristiche con bassa varianza (cioè che non apportano valore predittivo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Riduzione della dimensionalità**: processo di ridurre il numero di variabili casuali sotto considerazione, ottenendo un insieme di caratteristiche principali.\n",
    "\n",
    "    `sklearn.decomposition` contiene algoritmi per la decomposizione e la riduzione della dimensionalità dei dati, come l'*Analisi delle Componenti Principali* (PCA) e l'*Analisi delle Componenti Indipendenti* (ICA).\n",
    "\n",
    "    * `PCA`: tecnica di riduzione della dimensionalità che cerca di identificare nuove variabili (chiamate *componenti principali*) che sono combinazioni lineari delle variabili originali.\n",
    "    * `ICA`: tecnica di separazione dei segnali che cerca di trovare componenti che siano statisticamente indipendenti tra loro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Divisione del Dataset**\n",
    "Suddividere i dati in set di training e test per costruire e valutare il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.model_selection` include funzioni per la suddivisione dei dati in training e test set, la validazione incrociata (*cross-validation*) e la ricerca degli iperparametri ottimali tramite grid search o random search.\n",
    "\n",
    "    * `train_test_split()`: divide i dati in set di addestramento e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Selezione del Modello**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.ensemble` fornisce metodi di ensemble che combinano più modelli di base per migliorare le prestazioni predittive, tra cui Random Forest, Gradient Boosting e AdaBoost.\n",
    "\n",
    "    * `RandomForestClassifier()`, `RandomForestRegressor()`: algoritmi di foreste casuali per classificazione e regressione.\n",
    "    \n",
    "    * `GradientBoostingClassifier()`, `GradientBoostingRegressor()`: algoritmi di boosting per migliorare le prestazioni.\n",
    "\n",
    "    * `AdaBoostClassifier()`, `AdaBoostRegressor()`: implementazioni di AdaBoost, un metodo di ensemble che aggiunge iterativamente modelli deboli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Modelli di Regressione**: modelli per utilizzati per prevedere una variabile dipendente continua (tranne la *regressione logistica* utilizzata per classificazione) minimizzando l'errore tra le previsioni e i valori reali.\n",
    "\n",
    "    * **Regressione Lineare** è un modello statistico utilizzato per trovare una relazione *lineare* tra una variabile dipendente continua (*target*) e una o più variabili indipendenti.\n",
    "\n",
    "    * **Regressione Logistica** è un modello di classificazione utilizzato per prevedere la probabilità che un campione appartenga a una determinata classe. \n",
    "\n",
    "    *Funzione associata:*\n",
    "    \n",
    "    `sklearn.linear_model` include modelli lineari per la regressione e la classificazione, come regressione lineare, regressione logistica, lasso e ridge regression.\n",
    "\n",
    "    * `LinearRegression()`: regressione lineare.\n",
    "\n",
    "    * `LogisticRegression()`: regressione logistica per problemi di classificazione binaria o multi-classe.\n",
    "\n",
    "    * `Ridge()`, `Lasso()`, `ElasticNet()`: varianti della regressione lineare che aggiungono penalizzazioni per ridurre l'overfitting.\n",
    "\n",
    "    * `SGDClassifier()`, `SGDRegressor()`: *Stochastic Gradient Descent* per problemi di classificazione e regressione su grandi dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **Support Vector Machine (SVM)**: modelli di apprendimento supervisionato\n",
    "utilizzati per problemi di classificazione e regressione. Trovano l'iperpiano che massimizza il margine tra le classi, cioè la distanza tra i punti più vicini della classi, chiamati *support vector*.\n",
    "\n",
    "    *Funzione associata:*\n",
    "\n",
    "    `sklearn.svm` implementa le Macchine a Vettori di Supporto (SVM) per problemi di classificazione e regressione, utili per gestire dati ad alta dimensionalità.\n",
    "\n",
    "    * `SVC()`, `SVR()`: macchine a vettori di supporto per classificazione e regressione.\n",
    "\n",
    "    * `LinearSVC()`, `LinearSVR()`: versioni lineari delle SVM, più efficienti per grandi dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Alberi Decisionali**: modelli di apprendimento supervisionato non parametrico utilizzati sia per la classificazione che per la regressione. Suddividono i dati in base ai valori delle caratteristiche per fare\n",
    "previsioni.\n",
    "\n",
    "    *Funzione associata:*\n",
    "\n",
    "    `sklearn.tree` contiene algoritmi per la costruzione di alberi di decisione per la classificazione e la regressione, offrendo interpretabilità dei modelli.\n",
    "\n",
    "    * `DecisionTreeClassifier()`, `DecisionTreeRegressor()`: alberi decisionali per classificazione e regressione.\n",
    "\n",
    "    * `export_graphviz()`: visualizza graficamente un albero decisionale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Clustering**: tecnica di apprendimento non supervisionato che raggruppa i dati in cluster basandosi sulla similarità delle loro caratteristiche.\n",
    "\n",
    "    * **K-Means** è un algoritmo di clustering che raggruppa i dati in $k$ cluster basati sulla somiglianza delle caratteristiche.\n",
    "\n",
    "    *Funzione associata:*\n",
    "\n",
    "    `sklearn.cluster` offre metodi per il clustering non supervisionato, come K-Means, agglomerative clustering e DBSCAN, utili per scoprire strutture nascoste nei dati.\n",
    "\n",
    "    * `KMeans()`: algoritmo di clustering K-means.\n",
    "    \n",
    "    * `AgglomerativeClustering()`: clustering gerarchico agglomerativo.\n",
    "\n",
    "    * `DBSCAN()`: Clustering basato sulla densità.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **K-Nearest Neighbors (KNN)**: algoritmo di\n",
    "classificazione che assegna una classe a un'osservazione in base alle classi delle osservazioni più vicine in termini di distanza (spazio delle caratteristiche).\n",
    "\n",
    "    *Algoritmo*:\n",
    "    1. Calcola la distanza (tipicamente euclidea) tra il nuovo punto e tutti i punti nel dataset di training.\n",
    "    2. Seleziona i K punti più vicini.\n",
    "    3. Assegna la classe più frequente tra questi K punti al nuovo punto.\n",
    "\n",
    "    *Funzione associata*:\n",
    "\n",
    "    `sklearn.neighbors` implementa algoritmi basati sui vicini più prossimi, come K-Nearest Neighbors (KNN) per classificazione e regressione, e metodi per l'apprendimento basato sulla densità.\n",
    "\n",
    "    * `KNeighborsClassifier()`, `KNeighborsRegressor()`: classificazione e regressione basate sui vicini più prossimi (K-NN).\n",
    "    \n",
    "    * `NearestNeighbors()`: algoritmo per trovare i vicini più prossimi in problemi di clustering o ricerca di similarità."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.gaussian_process` offre metodi basati su processi gaussiani per la regressione e la classificazione probabilistica, fornendo stime con incertezza.\n",
    "\n",
    "    * `GaussianProcessRegressor()`: modelli di regressione basati su processi gaussiani.\n",
    "    \n",
    "    * `GaussianProcessClassifier()`: classificatori basati su processi gaussiani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Addestramento del Modello** \n",
    "Una volta scelto il modello si utilizza il metodo `model.fit()` per \n",
    "\n",
    "* imparare dai dati di addestramento: le caratteristiche (X) e le etichette/target (y) fornite vengono utilizzate per calcolare i parametri del modello.\n",
    "\n",
    "* costruire il modello: i parametri appresi permettono al modello di fare previsioni su nuovi dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Predizione**\n",
    "Dopo aver addestrato il modello, si può utilizzare `model.predict()` per\n",
    "\n",
    "* Fare previsioni su un insieme di test o su nuovi dati.\n",
    "\n",
    "* Restituire le etichette di classe (per problemi di classificazione) o i valori predetti (per problemi di regressione) in base ai dati forniti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Valutazione del Modello**\n",
    "La valutazione di un modello è il processo di misurazione della sua accuratezza o efficacia nel fare previsioni su dati non visti. Le metriche più diffuse sono\n",
    "\n",
    "* **Accuracy** (*problemi di classificazione*): misura la frazione di previsioni corrette rispetto al totale;\n",
    "\n",
    "* **Precision** (*problemi di classificazione binaria*): misura quanto il modello è preciso quando predice una classe positiva;\n",
    "\n",
    "* **Recall** (*problemi di classificazione binaria*): misura quanto bene il modello riesce a identificare tutte le istanze positive. \n",
    "\n",
    "* **F1-score** (*problemi di classificazione binaria*): fornisce un singolo valore che rappresenta un equilibrio tra precisione e recall. \n",
    "\n",
    "* **Mean Square Error (MSE)** (*problemi di regressione*): misura quanto le previsioni differiscono dai valori reali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.metrics` fornisce funzioni per valutare le prestazioni dei modelli attraverso metriche per classificazione, regressione e clustering, come accuratezza, precisione, recall e errore quadratico medio.\n",
    "\n",
    "* `accuracy_score()`: accuratezza del modello per classificazione.\n",
    "\n",
    "* `precision_score()`, `recall_score()`, `f1_score()`: metriche di precisione, recall e F1 per classificazione.\n",
    "\n",
    "* `mean_squared_error()`: errore quadratico medio per la regressione.\n",
    "\n",
    "* `confusion_matrix()`: matrice di confusione per analizzare le predizioni di un modello di classificazione.\n",
    "\n",
    "* `roc_auc_score()`: AUC-ROC per valutare le prestazioni del classificatore binario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Ottimizzazione**\n",
    "Si affina il modello regolando gli iperparametri o utilizzando tecniche come la validazione incrociata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.model_selection` include funzioni per la suddivisione dei dati in training e test set, la validazione incrociata (*cross-validation*) e la ricerca degli iperparametri ottimali tramite grid search o random search.\n",
    "\n",
    "    * `cross_val_score()`: esegue la validazione incrociata e restituisce le prestazioni del modello.\n",
    "\n",
    "    * `GridSearchCV()`: ricerca esaustiva degli iperparametri tramite grid search.\n",
    "\n",
    "    * `RandomizedSearchCV()`: ricerca casuale degli iperparametri.\n",
    "\n",
    "    * `KFold()`, `StratifiedKFold()`: suddivisione dei dati per *cross-validation*, mantenendo la distribuzione delle classi (*StratifiedKFold* per classificazione)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8. Implementazione**\n",
    "Una volta validato, il modello può essere utilizzato per fare previsioni su dati reali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sci-Py**\n",
    "\n",
    "SciPy è utilizzata per il calcolo scientifico e tecnico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queste sono le principali aree di lavoro e i moduli legati a essi.\n",
    "\n",
    "* Algebra Lineare `scipy.linalg`\n",
    "* Integrazione e Equazioni Differenziali\n",
    "`scipy.integrate`\n",
    "* Ottimizzazione `scipy.optimize`\n",
    "* Elaborazione del Segnale `scipy.signal`\n",
    "* Statistica `scipy.stats`\n",
    "* Trasformate di Fourier `scipy.fft`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Learning**\n",
    "Il *deep learning* è un sottocampo del *machine learning* che utilizza *reti neurali artificiali profonde* per comprendere e modellare conoscenze complesse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fasi del Deep Learning**\n",
    "\n",
    "1. Modello Sequenziale\n",
    "2. Modello Funzionale\n",
    "3. Strati (Layers)\n",
    "4. Compilazione del Modello\n",
    "5. Addestramento e Valutazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Differenza con il Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Struttura del Modello**:\n",
    "    - *Machine Learning*: Modelli più semplici o reti neurali con pochi strati.\n",
    "    - *Deep Learning*: Reti neurali con molti strati, capaci di apprendere rappresentazioni complesse.\n",
    "\n",
    "2. **Dati Necessari**:\n",
    "    - *Machine Learning*: Può funzionare bene con dataset di dimensioni moderate.\n",
    "    - *Deep Learning*: Richiede grandi quantità di dati per evitare overfitting e ottenere buone prestazioni.\n",
    "\n",
    "3. **Potenza Computazionale**:\n",
    "    - *Machine Learning*: Meno esigente in termini di risorse computazionali.\n",
    "    - *Deep Learning*: Richiede hardware potente (come GPU) per l'addestramento.\n",
    "\n",
    "4. **Feature Engineering**:\n",
    "    - *Machine Learning*: Spesso necessita di pre-elaborazione e selezione manuale delle caratteristiche.\n",
    "    - *Deep Learning*: Esegue l'apprendimento delle caratteristiche in modo autonomo.\n",
    "\n",
    "5. **Applicazioni Tipiche**:\n",
    "    - *Machine Learning*: Previsioni statistiche, analisi di dati strutturati, sistemi di raccomandazione.\n",
    "    - *Deep Learning*: Riconoscimento di immagini e voce, elaborazione del linguaggio naturale, guida autonoma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reti Neurali**\n",
    "\n",
    "Le *reti neurali* sono una classe di modelli nel machine learning ispirati al cervello umano, infatti sono composti da nodi (*neuroni*) organizzanti in strati (*layers*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Struttura Reti Neurali**\n",
    "\n",
    "* **Layers**: i dati vengono inseriti attraverso l'*input layer*, elaborati attraverso uno o più *hidden layers*, e l'output viene prodotto dal *output layer*.\n",
    "\n",
    "* **Connessioni**: le connessioni tra neuroni sono rappresenttate dalle freccie; ogni freccia trasporta l'output da un neurone all'altro ed è pesata da parametri che sono ottimizzati durante il processo di apprendimento.\n",
    "\n",
    "* **Processo di Apprendimento**: durante la fase di training, la rete neurale apprende ottimizzando questi pesi per minimizzare la differeza tra l'output previsto dalla rete e l'output effettivo (*target*); questo processo è guidato da un algoritmo di ottimizzazione e una *loss function* che misura l'errore di previsione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TensorFlow**\n",
    "Ottimizzato per il deep learning su larga scala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non si possono richiamare le funzioni tramite i nomi (non è nominale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Struttura di TensorFlow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Tensori**: array multidimensionale che rappresenta dati numerici; è la struttura base di TensorFlow.\n",
    "\n",
    "* **Grafi Computazionali**: rappresentano le operazioni matematiche; i nodi del grafo rappresentano operazioni matematiche, mentre gli spigoli rappresentano i tensori che fluiscono tra queste operazioni.\n",
    "\n",
    "* **Esecuzione Eager**: permette l'esecuzione immediata delle operazioni senza la necessità di costruire un grafo computazionale, rendendo il codice più intuitivo e simile a Python standard.\n",
    "\n",
    "* **Operazioni e Layers**: funzioni predefinite che eseguono calcoli su\n",
    "tensori, come operazioni matematiche, convoluzioni, pooling, ecc.\n",
    "\n",
    "* **Keras API Integrata**: incorporata per costruire e addestrare modelli di deep learning in modo più semplice e veloce.\n",
    "\n",
    "* **Dataset e Pipeline di Input**: consentono di caricare, pre-processare e\n",
    "gestire grandi quantità di dati in modo efficiente, utilizzando pipeline\n",
    "parallele e batching.\n",
    "\n",
    "* **Ottimizzatori**: algoritmi che aggiornano i pesi del modello per\n",
    "minimizzare la funzione di perdita, come SGD, Adam, RMSProp, ecc.\n",
    "\n",
    "* **Funzioni di Perdita**: misurano quanto il modello si discosta dai\n",
    "risultati attesi, guidando il processo di apprendimen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Keras**\n",
    "*Keras* è una libreria di TensorFlow scritto in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Struttura di Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Modello Sequenziale** : modelli di reti neurali dove gli strati sono organizzati in sequenza lineare; ogni strato ha esattamente un input e un output finali senza ramificazioni.\n",
    "\n",
    "    *Funzione associata*:\n",
    "    - `Sequential`\n",
    "    - `add`: permette di aggiungere un layer alla rete neurale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Modello Funzionale** : modelli più complessi che consententono la definizione di grafi computazionali arbitrari; è possibile costruire modelli con strati condivisi, percorsi multipli, ingressi e uscite multiple.\n",
    "\n",
    "    *Funzione associata*:\n",
    "    - `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(100,))\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Layers**: strato di  rete neurale composto da neuroni.\n",
    "\n",
    "    *Funzione associata*:\n",
    "    - `Dense` : permette di costruire un layer dati in input il numero di neuroni e la funzione di attivazione.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Compilazione del Modello**: traduce l'architettura definita in\n",
    "un modello efficiente pronto per essere addestrato sui dati.\n",
    "\n",
    "    *Funzione associata*:\n",
    "    - `compile`: permette di preparare il modello per l'addestramento inserendo in input ottimizzatore, la funzione di perdita e le metriche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Addestramento del Modello**: addestra il modello.\n",
    "\n",
    "    *Funzione associata*:\n",
    "    - `fit`: addestrare il modello sui dati di input e output inserendo\n",
    "        - *training set*\n",
    "        - *epochs* controllano quante volte l'intero dataset viene elaborato dal modello durante l'addestramento.\n",
    "        - *batch size* controlla quanti campioni vengono processati in ciascun passo dell'aggiornamento dei pesi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Valutazione e Predizione**: si valuta il modello sui dati di test e fare predizioni su nuovi dati.\n",
    "\n",
    "    *Funzione associata*:\n",
    "    - `evaluate` valuta il modello inserendo *test set* e *batch size*\n",
    "    - `predict`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PyTorch**\n",
    "Offre grafici computazionali dinamici che lo rendono ideale per la ricerca e lo sviluppo rapido di prototipi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
