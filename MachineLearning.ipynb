{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning**\n",
    "\n",
    "**Link codici** https://github.com/MaSTERmIKK/AulaMLandAI\n",
    "\n",
    "Il *machine learning* è un sottocampo dell'*intelligenza artificiale* che permette ai computer di imparare dai dati e migliorare le proprie prestazioni senza essere esplicitamente programmati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un modello è un costrutto matematico tra input e output desiderati. La costruzione avviene come segue:\n",
    "\n",
    "1. **Training**: Il modello viene realizzato tramite un processo di *addestramento*, ottimizzando i suoi parametri interni basandosi su un set di dati (*training set*).\n",
    "2. **Validation**: Dopo l'addestramento, i modelli vengono valutati su un set di dati di validazione (*validation set*) per regolare i parametri (*tuning*).\n",
    "3. **Testing**: Al termine testiamo il modello su un insieme di dati di test (*test set*) per valutare la performance finale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apprendimento Supervisionato**\n",
    "Il modello viene addestrato su un set di dati che include sia gli input che gli output (dati *etichettati*). L'obiettivo è costruire un modello che possa fare previsioni accurate su nuovi dati basandosi su questa corrispondenza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelli di apprendimento supervisionato sono:\n",
    " * *Classificazione*\n",
    " * *Regressione*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apprendimento Non Supervisionato**\n",
    "\n",
    "Il modello lavora con dati che non hanno output (dati *non etichettati*). L'obiettivo è scoprire strutture nascoste dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelli di apprendimento non supervisionato sono:\n",
    "* *Clustering* : raggruppa i dati simili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Apprendimento per Rinforzo**\n",
    "\n",
    "Tecnica in cui un agente impara a prendere decisione ottimizzando un sistema di ricompense e punizioni attraverso tentativi ed errori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overfitting e Underfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Overfitting**: si verifica quando un modello impara troppo bene i dettagli dei dati di addestramento, inclusi i rumori e le anomalie, a scapito delle prestazioni sui nuovi dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Underfitting**:  si verifica quando un modello è troppo semplice per catturare la struttura dei dati, risultando in una scarsa performance sia sui dati di addestramento che su quelli di test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reti Neurali**\n",
    "\n",
    "Le *reti neurali* sono una classe di modelli nel machine learning ispirati al cervello umano, infatti sono composti da nodi (*neuroni*) organizzanti in strati (*layers*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Struttura Reti Neurali**\n",
    "\n",
    "* **Layers**: i dati vengono inseriti attraverso l'*input layer*, elaborati attraverso uno o più *hidden layers*, e l'output viene prodotto dal *output layer*.\n",
    "\n",
    "* **Connessioni**: le connessioni tra neuroni sono rappresenttate dalle freccie; ogni freccia trasporta l'output da un neurone all'altro ed è pesata da parametri che sono ottimizzati durante il processo di apprendimento.\n",
    "\n",
    "* **Processo di Apprendimento**: durante la fase di training, la rete neurale apprende ottimizzando questi pesi per minimizzare la differeza tra l'output previsto dalla rete e l'output effettivo (*target*); questo processo è guidato da un algoritmo di ottimizzazione e una *loss function* che misura l'errore di previsione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librerie per Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Scikit-learn**\n",
    "Utilizzata per metodi tradizionali di machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Caricamento e Preparazione dei Dati**\n",
    "Dopo aver caricato i dati, si preprocessano i dati per pulirli e normalizzarli, rendoli adatti all'analisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.datasets` fornisce funzioni per caricare dataset di esempio e per generare dataset sintetici, utili per testare algoritmi e apprendere come utilizzare scikit-learn.\n",
    "\n",
    "    * `load_iris()`, `load_digits()`, `load_wine()`: funzioni per caricare dataset di esempio.\n",
    "    \n",
    "    * `make_classification()`, `make_regression()`, `make_blobs()`: funzioni per generare dataset sintetici utili per test e simulazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.preprocessing` contiene strumenti per pre-processare i dati, come la scalatura, la normalizzazione, la codifica delle variabili categoriche e la gestione dei dati mancanti.\n",
    "\n",
    "    * `StandardScaler()`: effettua la standardizzazione delle caratteristiche, rendendo media = 0 e deviazione standard = 1.\n",
    "    \n",
    "    * `MinMaxScaler()`: scala le caratteristiche in un intervallo specificato.\n",
    "\n",
    "    * `OneHotEncoder()`: codifica variabili categoriche in vettori binari.\n",
    "\n",
    "    * `LabelEncoder()`: Codifica etichette target trasformandole in numeri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.feature_selection` offre metodi per selezionare le caratteristiche più rilevanti nei dati, migliorando l'efficienza e le prestazioni dei modelli attraverso tecniche come l'eliminazione univariata e la selezione ricorsiva di caratteristiche.\n",
    "\n",
    "    * `SelectKBest()`: seleziona le migliori K caratteristiche in base a una funzione statistica.\n",
    "    \n",
    "    * `RFE()`: *Recursive Feature Elimination*, rimuove iterativamente le caratteristiche meno rilevanti.\n",
    "\n",
    "    * `VarianceThreshold()`: rimuove le caratteristiche con bassa varianza (cioè che non apportano valore predittivo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.decomposition` contiene algoritmi per la decomposizione e la riduzione della dimensionalità dei dati, come l'*Analisi delle Componenti Principali* (PCA) e l'*Analisi delle Componenti Indipendenti* (ICA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Divisione del Dataset**\n",
    "Suddividere i dati in set di training e test per costruire e valutare il modello."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.model_selection` include funzioni per la suddivisione dei dati in training e test set, la validazione incrociata (*cross-validation*) e la ricerca degli iperparametri ottimali tramite grid search o random search.\n",
    "\n",
    "    * `train_test_split()`: divide i dati in set di addestramento e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Selezione del Modello**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.ensemble` fornisce metodi di ensemble che combinano più modelli di base per migliorare le prestazioni predittive, tra cui Random Forest, Gradient Boosting e AdaBoost.\n",
    "\n",
    "    * `RandomForestClassifier()`, `RandomForestRegressor()`: algoritmi di foreste casuali per classificazione e regressione.\n",
    "    \n",
    "    * `GradientBoostingClassifier()`, `GradientBoostingRegressor()`: algoritmi di boosting per migliorare le prestazioni.\n",
    "\n",
    "    * `AdaBoostClassifier()`, `AdaBoostRegressor()`: implementazioni di AdaBoost, un metodo di ensemble che aggiunge iterativamente modelli deboli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.linear_model` include modelli lineari per la regressione e la classificazione, come regressione lineare, regressione logistica, lasso e ridge regression.\n",
    "\n",
    "    * `LinearRegression()`: regressione lineare.\n",
    "\n",
    "    * `LogisticRegression()`: regressione logistica per problemi di classificazione binaria o multi-classe.\n",
    "\n",
    "    * `Ridge()`, `Lasso()`, `ElasticNet()`: varianti della regressione lineare che aggiungono penalizzazioni per ridurre l'overfitting.\n",
    "\n",
    "    * `SGDClassifier()`, `SGDRegressor()`: *Stochastic Gradient Descent* per problemi di classificazione e regressione su grandi dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.svm` implementa le Macchine a Vettori di Supporto (SVM) per problemi di classificazione e regressione, utili per gestire dati ad alta dimensionalità.\n",
    "\n",
    "    * `SVC()`, `SVR()`: macchine a vettori di supporto per classificazione e regressione.\n",
    "\n",
    "    * `LinearSVC()`, `LinearSVR()`: versioni lineari delle SVM, più efficienti per grandi dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.tree` contiene algoritmi per la costruzione di alberi di decisione per la classificazione e la regressione, offrendo interpretabilità dei modelli.\n",
    "\n",
    "    * `DecisionTreeClassifier()`, `DecisionTreeRegressor()`: alberi decisionali per classificazione e regressione.\n",
    "    \n",
    "    * `export_graphviz()`: visualizza graficamente un albero decisionale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.cluster` offre metodi per il clustering non supervisionato, come K-Means, agglomerative clustering e DBSCAN, utili per scoprire strutture nascoste nei dati.\n",
    "\n",
    "    * `KMeans()`: algoritmo di clustering K-means.\n",
    "    \n",
    "    * `AgglomerativeClustering()`: clustering gerarchico agglomerativo.\n",
    "\n",
    "    * `DBSCAN()`: Clustering basato sulla densità.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **K-Nearest Neighbors (KNN)**: algoritmo di\n",
    "classificazione che assegna una classe a un'osservazione in base alle classi delle osservazioni più vicine in termini di distanza (spazio delle caratteristiche).\n",
    "\n",
    "    *Algoritmo*:\n",
    "    1. Calcola la distanza (tipicamente euclidea) tra il nuovo punto e tutti i punti nel dataset di training.\n",
    "    2. Seleziona i K punti più vicini.\n",
    "    3. Assegna la classe più frequente tra questi K punti al nuovo punto.\n",
    "\n",
    "    *Funzione associata*:\n",
    "\n",
    "    `sklearn.neighbors` implementa algoritmi basati sui vicini più prossimi, come K-Nearest Neighbors (KNN) per classificazione e regressione, e metodi per l'apprendimento basato sulla densità.\n",
    "\n",
    "    * `KNeighborsClassifier()`, `KNeighborsRegressor()`: classificazione e regressione basate sui vicini più prossimi (K-NN).\n",
    "    \n",
    "    * `NearestNeighbors()`: algoritmo per trovare i vicini più prossimi in problemi di clustering o ricerca di similarità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X, y)\n",
    "predictions = knn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.gaussian_process` offre metodi basati su processi gaussiani per la regressione e la classificazione probabilistica, fornendo stime con incertezza.\n",
    "\n",
    "    * `GaussianProcessRegressor()`: modelli di regressione basati su processi gaussiani.\n",
    "    \n",
    "    * `GaussianProcessClassifier()`: classificatori basati su processi gaussiani."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Addestramento del Modello** \n",
    "Una volta scelto il modello si utilizza il metodo `model.fit()` per \n",
    "\n",
    "* imparare dai dati di addestramento: le caratteristiche (X) e le etichette/target (y) fornite vengono utilizzate per calcolare i parametri del modello.\n",
    "\n",
    "* costruire il modello: i parametri appresi permettono al modello di fare previsioni su nuovi dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Predizione**\n",
    "Dopo aver addestrato il modello, si può utilizzare `model.predict()` per\n",
    "\n",
    "* Fare previsioni su un insieme di test o su nuovi dati.\n",
    "\n",
    "* Restituire le etichette di classe (per problemi di classificazione) o i valori predetti (per problemi di regressione) in base ai dati forniti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Valutazione del Modello**\n",
    "La valutazione di un modello è il processo di misurazione della sua accuratezza o efficacia nel fare previsioni su dati non visti. Le metriche più diffuse sono\n",
    "\n",
    "* **Accuracy** (*problemi di classificazione*): misura la frazione di previsioni corrette rispetto al totale;\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{Number of Correct Predictions}{Total Number of Predictions}\n",
    "$$\n",
    "\n",
    "* **Precision** (*problemi di classificazione binaria*): misura quanto il modello è preciso quando predice una classe positiva;\n",
    "$$\n",
    "Precision = \\frac{True Positives}{True Positives + False Positives}\n",
    "$$\n",
    "\n",
    "\n",
    "* **Recall** (*problemi di classificazione binaria*):\n",
    "\n",
    "* **F1-score** (*problemi di classificazione binaria*):\n",
    "\n",
    "* **Mean Square Error (MSE)** (*problemi di regressione*):misura quanto le previsioni differiscono dai valori reali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.metrics` fornisce funzioni per valutare le prestazioni dei modelli attraverso metriche per classificazione, regressione e clustering, come accuratezza, precisione, recall e errore quadratico medio.\n",
    "\n",
    "* `accuracy_score()`: accuratezza del modello per classificazione.\n",
    "\n",
    "* `precision_score()`, `recall_score()`, `f1_score()`: metriche di precisione, recall e F1 per classificazione.\n",
    "\n",
    "* `mean_squared_error()`: errore quadratico medio per la regressione.\n",
    "\n",
    "* `confusion_matrix()`: matrice di confusione per analizzare le predizioni di un modello di classificazione.\n",
    "\n",
    "* `roc_auc_score()`: AUC-ROC per valutare le prestazioni del classificatore binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [45, 150]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\curci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\curci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\curci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\curci\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [45, 150]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **7. Ottimizzazione**\n",
    "Si affina il modello regolando gli iperparametri o utilizzando tecniche come la validazione incrociata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `sklearn.model_selection` include funzioni per la suddivisione dei dati in training e test set, la validazione incrociata (*cross-validation*) e la ricerca degli iperparametri ottimali tramite grid search o random search.\n",
    "\n",
    "    * `cross_val_score()`: esegue la validazione incrociata e restituisce le prestazioni del modello.\n",
    "\n",
    "    * `GridSearchCV()`: ricerca esaustiva degli iperparametri tramite grid search.\n",
    "\n",
    "    * `RandomizedSearchCV()`: ricerca casuale degli iperparametri.\n",
    "\n",
    "    * `KFold()`, `StratifiedKFold()`: suddivisione dei dati per *cross-validation*, mantenendo la distribuzione delle classi (*StratifiedKFold* per classificazione)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **8. Implementazione**\n",
    "Una volta validato, il modello può essere utilizzato per fare previsioni su dati reali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TensorFlow**\n",
    "Ottimizzato per il deep learning su larga scala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PyTorch**\n",
    "Offre grafici computazionali dinamici che lo rendono ideale per la ricerca e lo sviluppo rapido di prototipi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
